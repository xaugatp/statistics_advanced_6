{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of Variance (ANNOVA) is a statistical method used to compare means among multile groups.\n",
    "To use the ANOVA test we made the following assumptions:\n",
    "-> Each group sample is drawn from a normally distrubted populations.\n",
    "-> All population have a common variance.\n",
    "-> All samples are drawn independently of each other. \n",
    "-> Within each sample, the observations are sampled randomly and independently of each other. \n",
    "-> Factors effectes of additive.\n",
    "\n",
    "\n",
    "Each group sample is drawn from a normally distributed population:\n",
    "\n",
    "Violation Example: If the data within a group is not normally distributed, ANOVA results may be affected. For instance, if a group has a skewed or heavily tailed distribution, it may violate the normality assumption.\n",
    "All populations have a common variance:\n",
    "\n",
    "Violation Example: Heterogeneous variances among groups can be a violation. For instance, if one group has a much larger variance than the others, it can impact the overall F-test, leading to potential issues in interpreting group differences.\n",
    "All samples are drawn independently of each other:\n",
    "\n",
    "Violation Example: If observations within a group are not independent (e.g., repeated measures or clustered data), it can violate the assumption of independence. This can occur when measurements on the same subject are taken over time or when there are dependencies within groups.\n",
    "Within each sample, the observations are sampled randomly and independently of each other:\n",
    "\n",
    "Violation Example: If the sampling within groups is not random or if there is a systematic bias in how samples are collected, it could violate the assumption. For instance, if certain subjects are more likely to be included in a specific group, it may compromise the randomness assumption.\n",
    "Factors' effects are additive:\n",
    "\n",
    "Violation Example: If there are interaction effects between factors, meaning the combined effect of two factors is not simply the sum of their individual effects, it can violate the additivity assumption. This occurs when the effect of one factor depends on the level of another, and it can complicate the interpretation of main effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three types of ANNOVA are :\n",
    "i) One Way ANOVA\n",
    "ii) Repeated Measures ANOVA\n",
    "iii) Factor ANOVA\n",
    "\n",
    "Situations when each could be used are: \n",
    "\n",
    "One-Way ANOVA:\n",
    "\n",
    "Use Case: One-Way ANOVA is used when there is one independent variable with more than two levels or groups, and the researcher wants to determine whether there are any statistically significant differences in the means of these groups. It is often applied to compare means across different categories or levels of a single factor.\n",
    "\n",
    "Example: Comparing the mean test scores of students from three different teaching methods (Method A, Method B, Method C) to determine if there is a significant difference in performance.\n",
    "\n",
    "Repeated Measures ANOVA:\n",
    "\n",
    "Use Case: Repeated Measures ANOVA is employed when the same subjects are used for each treatment or condition, and measurements are taken at multiple time points or under different conditions. It is particularly useful for studying changes within subjects over time or across different experimental conditions.\n",
    "\n",
    "Example: Assessing the effect of a drug treatment on blood pressure by measuring blood pressure before treatment, during treatment, and after treatment for each participant.\n",
    "\n",
    "Factorial ANOVA:\n",
    "\n",
    "Use Case: Factorial ANOVA is used when there are two or more independent variables (factors), and the researcher wants to examine their main effects and interactions on the dependent variable. This type of ANOVA is beneficial for exploring how different factors, both independently and in combination, influence the outcome.\n",
    "\n",
    "Example: Investigating the impact of both gender (Male/Female) and treatment type (A/B/C) on exam scores to examine not only the main effects of gender and treatment but also the interaction effect between gender and treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The partitioning of variance in ANOVA involves breaking down the total variability observed in the data into different components, specifically between-group variance and within-group variance. Here's an elaboration on the concept and its significance:\n",
    "\n",
    "Between-Group Variance:\n",
    "\n",
    "This component measures the extent to which the group means differ from each other. If the between-group variance is large relative to within-group variance, it suggests that there are significant differences among the group means. This is essential for understanding whether the independent variable (or factors) has a significant impact on the dependent variable.\n",
    "Within-Group Variance:\n",
    "\n",
    "Within-group variance represents the variability of individual data points within each group. It accounts for random variability and individual differences within groups. Understanding this component is crucial for capturing the natural variability that occurs within a group, which may be due to measurement error, individual differences, or other random factors.\n",
    "\n",
    "Understanding the partitioning of variance is important for several reasons:\n",
    "\n",
    "Hypothesis Testing:\n",
    "\n",
    "ANOVA uses the partitioning of variance to test whether the observed differences among group means are statistically significant. If the between-group variance is significantly larger than the within-group variance, it indicates that the groups are likely different from each other.\n",
    "Effectiveness of the Model:\n",
    "\n",
    "Assessing the partitioning of variance helps researchers evaluate how well the model explains the observed data. A large between-group variance suggests that the independent variable(s) has a substantial impact on the dependent variable.\n",
    "Identifying Sources of Variability:\n",
    "\n",
    "Understanding the breakdown of variance helps identify the sources of variability in the data. This is crucial for drawing meaningful conclusions about the factors influencing the dependent variable.\n",
    "Interpretation of F-ratio:\n",
    "\n",
    "The ratio of between-group variance to within-group variance (F-ratio) is used to determine the statistical significance of group differences. A high F-ratio suggests that the group means are not equal, and the observed differences are likely not due to chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 243.33333333333334\n",
      "Explained Sum of Squares (SSE): 123.33333333333333\n",
      "Residual Sum of Squares (SSR): 120.00000000000001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Example data (replace this with your actual data)\n",
    "group1 = np.array([12, 14, 16, 18, 20])\n",
    "group2 = np.array([8, 10, 12, 14, 16])\n",
    "group3 = np.array([5, 7, 9, 11, 13])\n",
    "\n",
    "# Combine the data into a single array\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "# Number of groups\n",
    "k = 3\n",
    "\n",
    "# Number of observations per group\n",
    "n = len(group1)\n",
    "\n",
    "# Calculate the mean of the entire dataset\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "# Calculate total sum of squares (SST)\n",
    "sst = np.sum((data - overall_mean)**2)\n",
    "\n",
    "# Calculate group means\n",
    "group_means = np.array([np.mean(group1), np.mean(group2), np.mean(group3)])\n",
    "\n",
    "# Calculate explained sum of squares (SSE)\n",
    "sse = np.sum(n * (group_means - overall_mean)**2)\n",
    "\n",
    "# Calculate residual sum of squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "# Display the results\n",
    "print(f\"Total Sum of Squares (SST): {sst}\")\n",
    "print(f\"Explained Sum of Squares (SSE): {sse}\")\n",
    "print(f\"Residual Sum of Squares (SSR): {ssr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect A p-value: 0.0536231380568786\n",
      "Main Effect B p-value: 0.3613861142296907\n",
      "Interaction Effect p-value: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sauga\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\scipy\\stats\\_stats_py.py:4141: DegenerateDataWarning: all input arrays have length 1.  f_oneway requires that at least one input has length greater than 1.\n",
      "  warnings.warn(stats.DegenerateDataWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "import pandas as pd \n",
    "# Create a sample dataset\n",
    "data = {'A': [1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
    "        'B': [1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
    "        'Value': [5, 8, 7, 10, 15, 12, 6, 9, 11]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extract unique levels for factors A and B\n",
    "levels_A = df['A'].unique()\n",
    "levels_B = df['B'].unique()\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "result_A = f_oneway(*[df['Value'][df['A'] == level] for level in levels_A])\n",
    "result_B = f_oneway(*[df['Value'][df['B'] == level] for level in levels_B])\n",
    "result_interaction = f_oneway(*[df['Value'][(df['A'] == level_A) & (df['B'] == level_B)] \n",
    "                                for level_A in levels_A for level_B in levels_B])\n",
    "\n",
    "# Extract p-values for main effects and interaction effect\n",
    "p_value_A = result_A.pvalue\n",
    "p_value_B = result_B.pvalue\n",
    "p_value_interaction = result_interaction.pvalue\n",
    "\n",
    "# Output results\n",
    "print(f\"Main Effect A p-value: {p_value_A}\")\n",
    "print(f\"Main Effect B p-value: {p_value_B}\")\n",
    "print(f\"Interaction Effect p-value: {p_value_interaction}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic is used to test whether there are significant differences among the means of three or more independent (unrelated) groups. The associated p-value indicates the probability of observing the given F-statistic under the null hypothesis, which assumes that all group means are equal.\n",
    "\n",
    "In your case:\n",
    "\n",
    "- F-statistic: 5.23\n",
    "- p-value: 0.02\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "1. **F-Statistic:**\n",
    "   - The F-statistic measures the ratio of the variance between groups to the variance within groups. A higher F-statistic suggests greater variability between group means relative to within-group variability.\n",
    "\n",
    "2. **P-Value:**\n",
    "   - The p-value of 0.02 is below the commonly used significance level of 0.05. This indicates that there is evidence to reject the null hypothesis.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "Given the obtained p-value of 0.02, you can conclude that there are statistically significant differences among the group means. In other words, at least one group mean is different from the others.\n",
    "\n",
    "### Interpretation of the Results:\n",
    "\n",
    "- **Rejection of the Null Hypothesis:**\n",
    "  - With a p-value of 0.02, you can reject the null hypothesis that all group means are equal.\n",
    "\n",
    "- **Practical Significance:**\n",
    "  - While statistical significance suggests differences between groups, it's also important to consider the practical significance of these differences. A small p-value doesn't necessarily imply a large or practically significant difference.\n",
    "\n",
    "- **Post-hoc Analysis:**\n",
    "  - If you have more than two groups, further post-hoc tests (e.g., Tukey's HSD, Bonferroni) may be conducted to identify which specific groups differ from each other.\n",
    "\n",
    "- **Effect Size:**\n",
    "  - Consider examining effect size measures (e.g., eta-squared or Cohen's d) to quantify the magnitude of the observed differences.\n",
    "\n",
    "In summary, you have evidence to suggest that there are significant differences among the group means based on the obtained F-statistic and p-value. Further analyses and exploration may be needed to understand the nature and implications of these differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling missing data in a repeated measures ANOVA is crucial for obtaining accurate and reliable results. The appropriate method for handling missing data depends on the nature of the missingness and the assumptions underlying the analysis. Here are some common approaches and their potential consequences:\n",
    "\n",
    "1. **Complete Case Analysis (CCA):**\n",
    "   - **Method:** Exclude cases with missing data from the analysis.\n",
    "   - **Consequences:**\n",
    "     - Reduces sample size.\n",
    "     - May introduce bias if missing data is not completely random (i.e., if there's a systematic reason for missingness).\n",
    "\n",
    "2. **Pairwise Deletion:**\n",
    "   - **Method:** Analyze each pair of variables with available data.\n",
    "   - **Consequences:**\n",
    "     - Utilizes all available data but may lead to biased results if missing data is related to the outcome.\n",
    "\n",
    "3. **Mean Imputation:**\n",
    "   - **Method:** Replace missing values with the mean of observed values for the variable.\n",
    "   - **Consequences:**\n",
    "     - Preserves sample size but underestimates variability and may distort relationships if missingness is not completely random.\n",
    "\n",
    "4. **Last Observation Carried Forward (LOCF):**\n",
    "   - **Method:** Use the last available measurement for missing values.\n",
    "   - **Consequences:**\n",
    "     - May not accurately represent changes over time, especially if missingness is related to changes in the variable.\n",
    "\n",
    "5. **Linear Interpolation:**\n",
    "   - **Method:** Estimate missing values based on the observed values before and after the missing point.\n",
    "   - **Consequences:**\n",
    "     - Assumes a linear trend, which may not be appropriate in all cases.\n",
    "\n",
    "6. **Multiple Imputation:**\n",
    "   - **Method:** Generate multiple datasets with imputed values and combine results.\n",
    "   - **Consequences:**\n",
    "     - Preserves variability and provides more accurate estimates if assumptions of missing data mechanism are met. However, it requires more complex statistical procedures.\n",
    "\n",
    "7. **Model-Based Imputation:**\n",
    "   - **Method:** Impute missing values using a model (e.g., regression).\n",
    "   - **Consequences:**\n",
    "     - Can provide accurate estimates if the imputation model is correctly specified. However, model misspecification can introduce bias.\n",
    "\n",
    "### Considerations:\n",
    "\n",
    "- **Missing Data Mechanism:**\n",
    "  - Understanding the mechanism of missingness is essential. If missing data is not missing completely at random (MCAR), other methods might be more appropriate.\n",
    "\n",
    "- **Sensitivity Analysis:**\n",
    "  - Perform sensitivity analyses using different imputation methods to assess the robustness of results.\n",
    "\n",
    "- **Consult Guidelines:**\n",
    "  - Follow guidelines and recommendations in the literature or statistical software documentation for handling missing data in the specific context of repeated measures ANOVA.\n",
    "\n",
    "- **Imputation Software:**\n",
    "  - Various statistical software packages (e.g., R, Python with libraries like `pandas` and `scikit-learn`) provide functions for implementing imputation techniques.\n",
    "\n",
    "Choosing the appropriate method requires careful consideration of the assumptions, potential biases, and the nature of the missing data. Multiple imputation is generally recommended when possible, as it accounts for uncertainty associated with imputed values and can provide more accurate results. However, it's important to ensure that the assumptions underlying imputation methods are met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-hoc tests are conducted after an analysis of variance (ANOVA) to further explore differences between specific groups when the overall ANOVA indicates a significant effect. Some common post-hoc tests include Tukey's Honestly Significant Difference (HSD), Bonferroni correction, Scheffé test, and Dunnett's test. The choice of post-hoc test depends on factors such as the assumptions, sample size, and research question. Here's an overview of these tests and when you might use each one:\n",
    "\n",
    "1. **Tukey's Honestly Significant Difference (HSD):**\n",
    "   - **When to use:**\n",
    "     - Useful when you have more than two groups and you want to compare all possible pairs.\n",
    "   - **Example:**\n",
    "     - In a study comparing the mean scores of three different teaching methods, if the overall ANOVA indicates a significant difference, Tukey's HSD can be used to identify which specific pairs of teaching methods differ significantly.\n",
    "\n",
    "2. **Bonferroni Correction:**\n",
    "   - **When to use:**\n",
    "     - Suitable when you have more than two groups and want to control the familywise error rate.\n",
    "   - **Example:**\n",
    "     - Suppose you are comparing mean scores of four different treatments. If the overall ANOVA is significant, and you want to conduct pairwise comparisons while controlling the overall Type I error rate, you might use Bonferroni correction.\n",
    "\n",
    "3. **Scheffé Test:**\n",
    "   - **When to use:**\n",
    "     - Appropriate when you have more than two groups and you want to control the familywise error rate, but it is generally more powerful than Bonferroni.\n",
    "   - **Example:**\n",
    "     - If you are conducting a study with multiple groups and the overall ANOVA is significant, Scheffé test can be used for pairwise comparisons to control the familywise error rate.\n",
    "\n",
    "4. **Dunnett's Test:**\n",
    "   - **When to use:**\n",
    "     - Specifically designed for comparing multiple treatments to a control group.\n",
    "   - **Example:**\n",
    "     - In a clinical trial comparing the effectiveness of several drugs to a placebo, if the overall ANOVA is significant, Dunnett's test can be used to compare each drug group to the control (placebo) group.\n",
    "\n",
    "### Example Scenario:\n",
    "\n",
    "Let's consider an experiment where researchers are testing the impact of three different diets (A, B, and C) on weight loss. After conducting a one-way ANOVA, if the overall test indicates a significant difference among the diets, you might decide to perform post-hoc tests to identify specific pairs of diets that differ significantly in terms of weight loss.\n",
    "\n",
    "- **Post-hoc Test Choice:**\n",
    "  - If you want to compare all pairs of diets, you could use Tukey's HSD.\n",
    "  - If you are particularly interested in comparing each diet to a control (e.g., a standard diet), Dunnett's test might be more appropriate.\n",
    "\n",
    "Remember, the choice of post-hoc test should be based on your specific research question, the nature of your data, and the assumptions of the chosen test. Always consider the context and the goals of your analysis when selecting a post-hoc test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 3.2675063109479887\n",
      "P-value: 0.040886324427914844\n",
      "There is a significant difference in mean weight loss between at least two diets.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Generate sample data\n",
    "data = {'Diet': ['A']*50 + ['B']*50 + ['C']*50,\n",
    "        'WeightLoss': [np.random.normal(loc=5, scale=2) for _ in range(50)] +\n",
    "                      [np.random.normal(loc=7, scale=2) for _ in range(50)] +\n",
    "                      [np.random.normal(loc=6, scale=2) for _ in range(50)]}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "result = f_oneway(df['WeightLoss'][df['Diet'] == 'A'],\n",
    "                  df['WeightLoss'][df['Diet'] == 'B'],\n",
    "                  df['WeightLoss'][df['Diet'] == 'C'])\n",
    "\n",
    "# Extract F-statistic and p-value\n",
    "f_statistic = result.statistic\n",
    "p_value = result.pvalue\n",
    "\n",
    "# Output results\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"There is a significant difference in mean weight loss between at least two diets.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in mean weight loss between the diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic Software: 27.37306260085701, p-value: 1.1673147268134069e-06\n",
      "F-statistic Experience: nan, p-value: nan\n",
      "F-statistic Interaction: 3.7680603721319503, p-value: 0.05551514343466879\n",
      "There is a significant difference in completion time between at least two software programs.\n",
      "There is no significant difference in completion time between novices and experienced users.\n",
      "There is no significant interaction effect between software programs and experience level.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sauga\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "C:\\Users\\sauga\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 1, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "C:\\Users\\sauga\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\model.py:1917: RuntimeWarning: invalid value encountered in divide\n",
      "  F /= J\n",
      "C:\\Users\\sauga\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\model.py:1888: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate sample data\n",
    "data = {'Software': ['A']*30 + ['B']*30 + ['C']*30,\n",
    "        'Experience': ['Novice']*45 + ['Experienced']*45,\n",
    "        'CompletionTime': [np.random.normal(loc=20, scale=5) for _ in range(30)] +\n",
    "                           [np.random.normal(loc=25, scale=5) for _ in range(30)] +\n",
    "                           [np.random.normal(loc=22, scale=5) for _ in range(30)]}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "formula = 'CompletionTime ~ C(Software) + C(Experience) + C(Software):C(Experience)'\n",
    "model = ols(formula, data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract F-statistics and p-values\n",
    "f_statistic_software = anova_table['F']['C(Software)']\n",
    "p_value_software = anova_table['PR(>F)']['C(Software)']\n",
    "\n",
    "f_statistic_experience = anova_table['F']['C(Experience)']\n",
    "p_value_experience = anova_table['PR(>F)']['C(Experience)']\n",
    "\n",
    "f_statistic_interaction = anova_table['F']['C(Software):C(Experience)']\n",
    "p_value_interaction = anova_table['PR(>F)']['C(Software):C(Experience)']\n",
    "\n",
    "# Output results\n",
    "print(f\"F-statistic Software: {f_statistic_software}, p-value: {p_value_software}\")\n",
    "print(f\"F-statistic Experience: {f_statistic_experience}, p-value: {p_value_experience}\")\n",
    "print(f\"F-statistic Interaction: {f_statistic_interaction}, p-value: {p_value_interaction}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value_software < 0.05:\n",
    "    print(\"There is a significant difference in completion time between at least two software programs.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in completion time between the software programs.\")\n",
    "\n",
    "if p_value_experience < 0.05:\n",
    "    print(\"There is a significant difference in completion time between novices and experienced users.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in completion time between novices and experienced users.\")\n",
    "\n",
    "if p_value_interaction < 0.05:\n",
    "    print(\"There is a significant interaction effect between software programs and experience level.\")\n",
    "else:\n",
    "    print(\"There is no significant interaction effect between software programs and experience level.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-statistic: -4.108723928204809\n",
      "P-value: 8.261945608702611e-05\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      " group1    group2    meandiff p-adj  lower   upper  reject\n",
      "----------------------------------------------------------\n",
      "Control Experimental   7.4325 0.0001 3.8427 11.0224   True\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)  # Setting seed for reproducibility\n",
    "control_group = np.random.normal(loc=70, scale=10, size=50)\n",
    "experimental_group = np.random.normal(loc=75, scale=10, size=50)\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({'Group': ['Control']*50 + ['Experimental']*50,\n",
    "                     'TestScores': np.concatenate([control_group, experimental_group])})\n",
    "\n",
    "# Conduct two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(data['TestScores'][data['Group'] == 'Control'],\n",
    "                                 data['TestScores'][data['Group'] == 'Experimental'])\n",
    "\n",
    "# Output t-test results\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Follow up with post-hoc test (Tukey's HSD)\n",
    "posthoc = pairwise_tukeyhsd(data['TestScores'], data['Group'], alpha=0.05)\n",
    "\n",
    "# Display post-hoc results\n",
    "print(posthoc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 4.085968889697053\n",
      "P-value: 0.02013491576502835\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      "group1 group2 meandiff p-adj   lower    upper  reject\n",
      "-----------------------------------------------------\n",
      "     A      B  11.9455 0.0506   -0.025  23.916  False\n",
      "     A      C  -0.9149 0.9819 -12.8854 11.0555  False\n",
      "     B      C -12.8604 0.0322 -24.8309   -0.89   True\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)  # Setting seed for reproducibility\n",
    "store_a_sales = np.random.normal(loc=100, scale=20, size=30)\n",
    "store_b_sales = np.random.normal(loc=110, scale=15, size=30)\n",
    "store_c_sales = np.random.normal(loc=95, scale=25, size=30)\n",
    "\n",
    "# Create DataFrame\n",
    "data = pd.DataFrame({'Store': ['A']*30 + ['B']*30 + ['C']*30,\n",
    "                     'Sales': np.concatenate([store_a_sales, store_b_sales, store_c_sales])})\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "result = f_oneway(data['Sales'][data['Store'] == 'A'],\n",
    "                  data['Sales'][data['Store'] == 'B'],\n",
    "                  data['Sales'][data['Store'] == 'C'])\n",
    "\n",
    "# Extract F-statistic and p-value\n",
    "f_statistic = result.statistic\n",
    "p_value = result.pvalue\n",
    "\n",
    "# Output one-way ANOVA results\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Follow up with post-hoc test (Tukey's HSD)\n",
    "posthoc = pairwise_tukeyhsd(data['Sales'], data['Store'], alpha=0.05)\n",
    "\n",
    "# Display post-hoc results\n",
    "print(posthoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
